{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbe40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/preprocessed_train_data/audio/5a03d20a7ecfc50001be0a7a_q1_generic.pt')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"../data/preprocessed_train_data\")\n",
    "audio_dir = data_dir / \"audio\"\n",
    "\n",
    "audio_path = sorted(audio_dir.glob(\"*.pt\"))[0]\n",
    "audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9c5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1969, -0.0129, -0.0882,  ...,  0.1390,  0.2094, -0.1379],\n",
       "         [ 0.0950,  0.0111, -0.0779,  ...,  0.0576,  0.1827, -0.2337],\n",
       "         [ 0.0894,  0.0031, -0.0777,  ...,  0.0161,  0.2006, -0.1645],\n",
       "         ...,\n",
       "         [-0.1300, -0.0172,  0.1780,  ...,  0.1942,  0.2564, -0.2170],\n",
       "         [-0.0504, -0.0843,  0.2044,  ...,  0.3398,  0.2339, -0.1538],\n",
       "         [ 0.0152, -0.0241,  0.1738,  ...,  0.4174,  0.0609, -0.0242]]),\n",
       " torch.Size([20679, 768]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "audio_tensor = torch.load(audio_path)\n",
    "audio_tensor, audio_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5aceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generally my greatest strength as an employee is my empathy. I'm very good at communicating with others because I'm very good at understanding where they're coming from. Even when they're upset, I can usually deal with people without getting to upset myself. And on the other side of that, my greatest weakness as an employee is that I'm kind of shy. I'm good at talking to people in a little community and to people that I don't really like to be very social like with my coworkers. But I'm good at dealing with customers.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"temp.wav\", temperature=0)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers.logging.set_verbosity_error()\n",
    "\n",
    "# model_id = \"facebook/wav2vec2-base\"\n",
    "# model = Wav2Vec2ForCTC.from_pretrained(\n",
    "#     model_id, use_safetensors=True\n",
    "# ).to(args.audio_model_device)\n",
    "# processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# val_file_paths = sorted(VAL_DIR_PATH.glob(\"*.mp4\"))\n",
    "\n",
    "# emoti_eff: EmotiEffLibRecognizerBase = EmotiEffLibRecognizer(\n",
    "#     model_name=\"enet_b0_8_best_vgaf\",\n",
    "#     device=args.video_model_device,\n",
    "#     engine=\"torch\",\n",
    "# )\n",
    "\n",
    "\n",
    "# features: list[np.ndarray] = []\n",
    "# batch_size = 32\n",
    "# for i in range(0, len(cropped_frames), batch_size):\n",
    "#     batch = cropped_frames[i : i + batch_size]\n",
    "#     batch_features = emoti_eff.extract_features(batch)\n",
    "#     features.extend(batch_features)\n",
    "\n",
    "# # boost performance of conversions list[np.ndarray] -> np.ndarray\n",
    "# features = np.array(features)\n",
    "# video_features: Float[torch.Tensor, \"frames features\"] = (  # noqa: F722\n",
    "#     torch.from_numpy(features)\n",
    "# )\n",
    "# torch.save(\n",
    "#     obj=video_features,\n",
    "#     f=preprocessed_dir_path / \"video\" / f\"{sample_path.stem}.pt\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
